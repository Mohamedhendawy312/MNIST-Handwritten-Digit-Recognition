# MNIST Digit Recognition with PyTorch

A deep learning approach to handwritten digit recognition using Convolutional Neural Networks (CNNs). Built with modern Python practices including type hints, modular architecture, and comprehensive documentation.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)
![Accuracy](https://img.shields.io/badge/Accuracy-99.37%25-brightgreen)
![License](https://img.shields.io/badge/License-MIT-yellow)

---

## ğŸ“Š Results

| Metric | Value |
|--------|-------|
| **Test Accuracy** | 99.37% |
| **Precision** | 99.38% |
| **Recall** | 99.37% |
| **F1 Score** | 99.37% |

### Training & Validation Curves

<p align="center">
  <img src="outputs/training_curves.png" alt="Training Curves" width="800"/>
</p>

### Confusion Matrix

<p align="center">
  <img src="outputs/confusion_matrix.png" alt="Confusion Matrix" width="600"/>
</p>

### Sample Predictions

<p align="center">
  <img src="outputs/sample_predictions.png" alt="Sample Predictions" width="700"/>
</p>

---

## ğŸ—ï¸ Model Architecture

```
ImprovedNet (422,474 parameters)
â”œâ”€â”€ Conv2d(1, 32, 3x3) + BatchNorm + ReLU + MaxPool
â”œâ”€â”€ Conv2d(32, 64, 3x3) + BatchNorm + ReLU + MaxPool  
â”œâ”€â”€ Conv2d(64, 128, 3x3) + BatchNorm + ReLU + MaxPool
â”œâ”€â”€ Flatten â†’ 1152
â”œâ”€â”€ Linear(1152, 256) + ReLU + Dropout(0.25)
â”œâ”€â”€ Linear(256, 128) + ReLU
â””â”€â”€ Linear(128, 10) â†’ Output
```

**Also available:** `ResidualCNN` - A deeper architecture with skip connections for potentially higher accuracy.

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- CUDA-compatible GPU (optional, but recommended)

### Installation

```bash
# Clone the repository
git clone https://github.com/Mohamedhendawy312/MNIST-Handwritten-Digit-Recognition.git
cd MNIST-Handwritten-Digit-Recognition

# Create conda environment (recommended)
conda create -n mnist python=3.10 -y
conda activate mnist

# Install dependencies
pip install -r requirements.txt
```

### Training

```bash
# Train the model (downloads MNIST automatically)
python -m src.train
```

Training takes ~3 minutes on a modern GPU or ~10 minutes on CPU.

### Evaluation

```bash
# Evaluate on test set
python -m src.evaluate
```

### Generate Visualizations

```bash
# Generate confusion matrix, training curves, and sample predictions
python -m src.visualize
```

---

## ğŸ“ Project Structure

```
MNIST-Handwritten-Digit-Recognition/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py       # Package exports
â”‚   â”œâ”€â”€ config.py         # Configuration & hyperparameters
â”‚   â”œâ”€â”€ model.py          # CNN architectures (ImprovedNet, ResidualCNN)
â”‚   â”œâ”€â”€ utils.py          # Data loading & augmentation
â”‚   â”œâ”€â”€ train.py          # Training pipeline
â”‚   â”œâ”€â”€ evaluate.py       # Evaluation & metrics
â”‚   â””â”€â”€ visualize.py      # Visualization utilities
â”œâ”€â”€ models/               # Saved model checkpoints
â”œâ”€â”€ outputs/              # Generated visualizations
â”œâ”€â”€ data/                 # MNIST data (auto-downloaded)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

All hyperparameters are centralized in `src/config.py`:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `batch_size` | 128 | Training batch size |
| `learning_rate` | 0.001 | Initial learning rate |
| `epochs` | 20 | Number of training epochs |
| `dropout_rate` | 0.25 | Dropout for regularization |
| `model_name` | "improved" | Architecture ("improved" or "residual") |

### Using a Different Model

```python
from src.config import Config

config = Config(model_name="residual")  # Use ResidualCNN instead
```

---

## ğŸ“ˆ Data Augmentation

Training uses the following augmentations for better generalization:

- **Random Rotation**: Â±10Â°
- **Random Affine**: Translation (Â±10%), Scale (0.9-1.1x)
- **Normalization**: Mean=0.1307, Std=0.3081 (MNIST statistics)

---

## ğŸ› ï¸ Development

This project follows clean code conventions:

- âœ… Type hints throughout
- âœ… Google-style docstrings
- âœ… Modular architecture
- âœ… Reproducible (seeded random states)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Mohamed Hendawy**

- GitHub: [@Mohamedhendawy312](https://github.com/Mohamedhendawy312)
- Email: mohamedhendawy312@gmail.com
